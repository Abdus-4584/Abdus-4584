{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-python-client\n",
    "#pip install --upgrade google-cloud-storage\n",
    "#pip install --upgrade google-cloud-spanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84990256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ibm_db_dbi as idb\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import warnings\n",
    "import pyvalidata as pvd\n",
    "import hashlib\n",
    "#import time \n",
    "#import datetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import ibm_db_sa\n",
    "import csv\n",
    "from google.cloud import storage\n",
    "from google.cloud import spanner\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import spanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e47f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"kr-7738-supvis-t-3e70a14d235d_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0174fdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to udm-db (database 1) successful.\n",
      "Connection to storewalks-db (database 2) successful.\n"
     ]
    }
   ],
   "source": [
    "#projects/kr-7738-supvis-t/instances/nc-event-sink-instance/databases/storewalks-db\n",
    "\n",
    "# Your Cloud Spanner instance ID.\n",
    "instance_id = \"nc-event-sink-instance\"\n",
    "\n",
    "# Your Cloud Spanner database ID.\n",
    "database_id_1 = \"udm-db\"\n",
    "database_id_2 = \"storewalks-db\"\n",
    "\n",
    "# Instantiate a client.\n",
    "spanner_client = spanner.Client()\n",
    "\n",
    "# Get a Cloud Spanner instance by ID.\n",
    "instance = spanner_client.instance(instance_id)\n",
    "\n",
    "# Get a Cloud Spanner database by ID (for database_id_1).\n",
    "database_1 = instance.database(database_id_1)\n",
    "print(\"Connection to udm-db (database 1) successful.\")\n",
    "\n",
    "# Get a Cloud Spanner database by ID (for database_id_1).\n",
    "database_2 = instance.database(database_id_2)\n",
    "print(\"Connection to storewalks-db (database 2) successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e267bd",
   "metadata": {},
   "source": [
    "## 1) Daily Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60a5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_id_1 = \"udm-db\"  & instance_id = \"nc-event-sink-instance\" (Source Query)\n",
    "\n",
    "#Source Data\n",
    "with database_1.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "        SELECT * FROM (\n",
    "            SELECT\n",
    "                div_str_id AS div_str_id_s,\n",
    "                task_type_name,\n",
    "                task_classification AS task_classification_s,\n",
    "                a.task_desc,\n",
    "            FROM\n",
    "                (SELECT * FROM santn_rotn_task_mstr) a\n",
    "                JOIN (SELECT * FROM sub_dpmt_mpng) b USING (sub_dpmt_id)\n",
    "                JOIN (SELECT * FROM str_dpmt_mpng) c ON c.dpmt_name = b.prmry_dpmt_name\n",
    "                LEFT JOIN (SELECT * FROM rolng_task_addtnl_info) d\n",
    "                    ON (a.santn_rotn_task_mstr_id = d.santn_rotn_task_mstr_id)\n",
    "            WHERE\n",
    "                a.is_actv = 'Y'\n",
    "                AND c.is_actv = 'Y'\n",
    "                AND DATE(strt_date) = '2023-09-05'\n",
    "                --AND strt_date <= '2023-09-05'\n",
    "                AND task_classification LIKE 'Daily'\n",
    "                AND div_str_id = '53100515'\n",
    "            UNION ALL\n",
    "            SELECT\n",
    "                div_str_id AS div_str_id_s,\n",
    "                task_type_name,\n",
    "                task_classification AS task_classification_s,\n",
    "                a.task_desc,\n",
    "            FROM\n",
    "                (SELECT * FROM santn_rotn_task_mstr) a\n",
    "                JOIN (SELECT * FROM sub_dpmt_mpng) b USING (sub_dpmt_id)\n",
    "                JOIN (SELECT * FROM str_dpmt_mpng) c ON c.dpmt_name = b.prmry_dpmt_name\n",
    "                LEFT JOIN (SELECT * FROM santn_rotn_task_schdl) d\n",
    "                    ON (a.santn_rotn_task_mstr_id = d.santn_rotn_task_mstr_id)\n",
    "            WHERE\n",
    "                a.is_actv = 'Y'\n",
    "                AND c.is_actv = 'Y'\n",
    "                AND DATE(schd_strt_date) = '2023-09-05'\n",
    "                --AND schd_strt_date <= '2023-09-05'\n",
    "                AND task_classification LIKE 'Daily'\n",
    "                AND div_str_id = '53100515'\n",
    "        ) Daily_S\n",
    "    \"\"\")\n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_s_df = pd.DataFrame(rows, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fcf50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 44\n",
      "Number of columns: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div_str_id_s</th>\n",
       "      <th>task_type_name</th>\n",
       "      <th>task_classification_s</th>\n",
       "      <th>task_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Clean/Sweep - Work Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Wipe Down - Prep Area Work Tables and Scales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Take Out Trash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Sweep Pick-up Cooler Floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Vestibule Maintenance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  div_str_id_s task_type_name task_classification_s  \\\n",
       "0     53100515     Sanitation                 Daily   \n",
       "1     53100515     Sanitation                 Daily   \n",
       "2     53100515     Sanitation                 Daily   \n",
       "3     53100515     Sanitation                 Daily   \n",
       "4     53100515     Sanitation                 Daily   \n",
       "\n",
       "                                      task_desc  \n",
       "0                       Clean/Sweep - Work Area  \n",
       "1  Wipe Down - Prep Area Work Tables and Scales  \n",
       "2                                Take Out Trash  \n",
       "3                    Sweep Pick-up Cooler Floor  \n",
       "4                         Vestibule Maintenance  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows, num_columns = result_s_df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "result_s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2280ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_id_2 = \"storewalks-db\"  & instance_id = \"nc-event-sink-instance\"\n",
    "#Target Data\n",
    "with database_2.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "        SELECT\n",
    "            CONCAT(division_number, store_number) AS div_str_id,\n",
    "            task_type,\n",
    "            task_classification,\n",
    "            task_description,\n",
    "        FROM\n",
    "            task\n",
    "        WHERE\n",
    "            task_type <> 'Green Rack'\n",
    "            AND task_classification LIKE 'Daily'\n",
    "            AND task_date = '2023-09-05'\n",
    "            AND CONCAT(division_number, store_number) = '53100515'\n",
    "    \"\"\")\n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_t_df = pd.DataFrame(rows, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b930b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 44\n",
      "Number of columns: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div_str_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_classification</th>\n",
       "      <th>task_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Wipe Down - Glass Doors on Sales Floor Display...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Clean - Cutting Room 3-compt Sink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Spray and Wipe - Prep Room Weigh Scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Clean - Parking Lot and Sidewalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Spray and Wipe - Food Preparation Tables</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  div_str_id   task_type task_classification  \\\n",
       "0   53100515  Sanitation               Daily   \n",
       "1   53100515  Sanitation               Daily   \n",
       "2   53100515  Sanitation               Daily   \n",
       "3   53100515  Sanitation               Daily   \n",
       "4   53100515  Sanitation               Daily   \n",
       "\n",
       "                                    task_description  \n",
       "0  Wipe Down - Glass Doors on Sales Floor Display...  \n",
       "1                  Clean - Cutting Room 3-compt Sink  \n",
       "2             Spray and Wipe - Prep Room Weigh Scale  \n",
       "3                   Clean - Parking Lot and Sidewalk  \n",
       "4           Spray and Wipe - Food Preparation Tables  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows, num_columns = result_t_df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "result_t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab13a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Validation Report Passed\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'div_str_id' and 'task_desc'\n",
    "merged_df = pd.merge(result_s_df, result_t_df, left_on=['div_str_id_s', 'task_desc'], right_on=['div_str_id', 'task_description'], how='outer')\n",
    "\n",
    "# Create a new column 'ComparisonResult' based on your conditions\n",
    "merged_df['ComparisonResult'] = 'Mismatch'\n",
    "\n",
    "# Condition 1: Matched\n",
    "condition_matched = (\n",
    "    (merged_df['task_type_name'] == merged_df['task_type']) &\n",
    "    (merged_df['task_classification_s'] == merged_df['task_classification']) &\n",
    "    #(merged_df['sub_dpmt_name'] == merged_df['department_name']) &\n",
    "    (merged_df['task_desc'] == merged_df['task_description'])\n",
    "    #(merged_df['concatenated_s'] == merged_df['concatenated_t'])\n",
    ")\n",
    "merged_df.loc[condition_matched, 'ComparisonResult'] = 'Matched'\n",
    "\n",
    "# Condition 2: Record NOT in Target\n",
    "condition_not_in_target = (merged_df['div_str_id_s'].notna()) & (merged_df['div_str_id'].isna())\n",
    "merged_df.loc[condition_not_in_target, 'ComparisonResult'] = 'Record NOT in Target'\n",
    "\n",
    "# Condition 3: Record NOT in Source\n",
    "condition_not_in_source = (merged_df['div_str_id'].notna()) & (merged_df['div_str_id_s'].isna())\n",
    "merged_df.loc[condition_not_in_source, 'ComparisonResult'] = 'Record NOT in Source'\n",
    "\n",
    "# Remove duplicates from merged_df\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "# Reset the index after removing duplicates (optional)\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if there are any failed records\n",
    "if not failed_records.empty:\n",
    "    print('Daily Validation Report Failed')\n",
    "\n",
    "    # Get the current date as a timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Define the full path to save the report file\n",
    "    file_path = r'C:\\\\Users\\\\AS81970\\\\Desktop\\\\2023 Q3\\\\Store Walk-in\\\\Reports'\n",
    "    \n",
    "    # Define the file name with the date appended\n",
    "    report_file_name = f'Daily_Validation_Report_Failed_{timestamp}.xlsx'\n",
    "    \n",
    "    # Save the failed records to an Excel file with the generated file name\n",
    "    failed_records.to_excel(f'{file_path}\\\\{report_file_name}', index=False)\n",
    "else:\n",
    "    print('Daily Validation Report Passed')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1141c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f38b5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source Counts\n",
    "with database_1.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    " select sum(count), 'daily_s'  \n",
    "from    \n",
    " (\n",
    " (select  distinct count(*) as count,div_str_id, task_type_name, task_classification,sub_dpmt_name \n",
    "            FROM\n",
    "                (SELECT * FROM santn_rotn_task_mstr) a\n",
    "                JOIN (SELECT * FROM sub_dpmt_mpng) b USING (sub_dpmt_id)\n",
    "                JOIN (SELECT * FROM str_dpmt_mpng) c ON c.dpmt_name = b.prmry_dpmt_name\n",
    "                LEFT JOIN (SELECT * FROM rolng_task_addtnl_info) d\n",
    "                    ON (a.santn_rotn_task_mstr_id = d.santn_rotn_task_mstr_id)\n",
    "            WHERE\n",
    "                a.is_actv = 'Y'\n",
    "                AND c.is_actv = 'Y'\n",
    "                AND DATE(strt_date) = '2023-09-05'\n",
    "                --AND strt_date <= '2023-09-05'\n",
    "                AND task_classification LIKE 'Daily'\n",
    "group by div_str_id, task_type_name, task_classification,sub_dpmt_name)  \n",
    "union all\n",
    "(select  distinct count(*) as count,div_str_id, task_type_name, task_classification,sub_dpmt_name \n",
    "            FROM\n",
    "                (SELECT * FROM santn_rotn_task_mstr) a\n",
    "                JOIN (SELECT * FROM sub_dpmt_mpng) b USING (sub_dpmt_id)\n",
    "                JOIN (SELECT * FROM str_dpmt_mpng) c ON c.dpmt_name = b.prmry_dpmt_name\n",
    "                LEFT JOIN (SELECT * FROM santn_rotn_task_schdl) d\n",
    "                    ON (a.santn_rotn_task_mstr_id = d.santn_rotn_task_mstr_id)\n",
    "            WHERE\n",
    "                a.is_actv = 'Y'\n",
    "                AND c.is_actv = 'Y'\n",
    "                AND DATE(schd_strt_date) = '2023-09-05'\n",
    "                --AND schd_strt_date <= '2023-09-05'\n",
    "                AND task_classification LIKE 'Daily'\n",
    "group by div_str_id, task_type_name, task_classification,sub_dpmt_name) \n",
    ")   \n",
    "    \n",
    "        \"\"\")\n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_s_c_df = pd.DataFrame(rows, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1ccf252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109079</td>\n",
       "      <td>daily_s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  \n",
       "0  109079  daily_s"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_s_c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f2c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source Counts\n",
    "with database_2.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "select sum(count1), 'daily_t' \n",
    "from \n",
    "(select count(*) as count1,division_number, store_number, task_type, task_classification,department_name, task_date, task_status \n",
    "from  task\n",
    "where task_type<>'Green Rack' and task_classification like 'Daily' and task_date='2023-09-05'\n",
    "group by division_number, store_number, task_type, task_classification,department_name, task_date, task_status\n",
    ")\n",
    "        \"\"\")\n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_t_c_df = pd.DataFrame(rows, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87460b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108989</td>\n",
       "      <td>daily_t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  \n",
       "0  108989  daily_t"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_t_c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c7f195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current timestamp\n",
    "timestamp_c = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define the file path\n",
    "file_path_c = f\"C:\\\\Users\\\\AS81970\\\\Desktop\\\\2023 Q3\\\\Store Walk-in\\\\Reports\\\\Count_{timestamp_c}.csv\"\n",
    "\n",
    "# Write the DataFrames to the CSV file\n",
    "result_s_c_df.to_csv(file_path_c, index=False)\n",
    "result_t_c_df.to_csv(file_path_c, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5323372",
   "metadata": {},
   "source": [
    "## 2) Weekly Sanitation Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca57a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75aefb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "904990b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source data1\n",
    "with database_1.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "select * from\n",
    "(\n",
    "select div_str_id,a.task_desc,a.task_type, task_type_name, task_classification,sub_dpmt_name\n",
    "from (SELECT * FROM santn_rotn_Task_mstr) a \n",
    "join (SELECT * FROM sub_dpmt_mpng) b using(sub_dpmt_id) \n",
    "join (SELECT * FROM str_dpmt_mpng) c on c.dpmt_name=b.prmry_dpmt_name \n",
    "left join (SELECT * FROM rolng_task_addtnl_info)  d on (a.santn_rotn_task_mstr_id=d.santn_rotn_task_mstr_id)  \n",
    "where a.is_actv='Y' and c.is_actv='Y' and DATE(strt_date) >='2023-08-30' and DATE(strt_date) <='2023-09-05' and task_classification  like 'Weekly' and div_str_id ='53100515'\n",
    "union all \n",
    "select div_str_id,a.task_desc,a.task_type, task_type_name, task_classification,sub_dpmt_name\n",
    "from (SELECT * FROM santn_rotn_Task_mstr) a \n",
    "join (SELECT * FROM sub_dpmt_mpng) b using(sub_dpmt_id) \n",
    "join (SELECT * FROM str_dpmt_mpng) c on c.dpmt_name=b.prmry_dpmt_name \n",
    "left join (SELECT * FROM santn_rotn_task_schdl)  d on (a.santn_rotn_task_mstr_id=d.santn_rotn_task_mstr_id) \n",
    "where a.is_actv='Y' and c.is_actv='Y' and DATE(schd_strt_date) >='2023-08-30' and DATE(schd_strt_date) <='2023-09-05' and task_classification  like 'Weekly' and div_str_id ='53100515'\n",
    ") \n",
    "\n",
    " \"\"\")\n",
    "    \n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_ws_s1_df = pd.DataFrame(rows, columns = cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0147126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source data2\n",
    "with database_2.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "select \n",
    "concat(division_number,store_number) AS div_str_id,\n",
    "task_type, task_classification, department_name, task_description\n",
    "from task\n",
    "where task_type='Sanitation' \n",
    "and task_classification like 'Weekly' \n",
    "and task_date='2023-09-04' \n",
    "and task_status='To Do'\n",
    "        \"\"\")\n",
    "    \n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_ws_s2_df = pd.DataFrame(rows, columns = cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da297580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the DataFrames using the specified conditions\n",
    "result_ws_s_df = pd.merge(result_ws_s1_df, result_ws_s2_df, how='inner', left_on=[\n",
    "    'div_str_id', 'task_type_name', 'task_classification','sub_dpmt_name', 'task_desc'\n",
    "], right_on=[\n",
    "    'div_str_id', 'task_type', 'task_classification', 'department_name', 'task_description'\n",
    "])\n",
    "\n",
    "# Select the desired columns in the result_df DataFrame\n",
    "result_ws_s_df = result_ws_s_df[['div_str_id', 'task_desc', 'task_type_x', 'task_type_name', 'task_classification', 'sub_dpmt_name']]\n",
    "\n",
    "# Rename the columns in the result_df DataFrame\n",
    "result_ws_s_df = result_ws_s_df.rename(columns={\n",
    "    'div_str_id': 'div_str_id_s',\n",
    "    'task_type_x': 'task_type_name',\n",
    "    'task_classification': 'task_classification_s',\n",
    "    'task_desc': 'task_desc',\n",
    "    'sub_dpmt_name': 'sub_dpmt_name'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02ae7c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div_str_id_s</th>\n",
       "      <th>task_desc</th>\n",
       "      <th>task_type_name</th>\n",
       "      <th>task_type_name</th>\n",
       "      <th>task_classification_s</th>\n",
       "      <th>sub_dpmt_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Deep Clean - Knife Racks</td>\n",
       "      <td>Weekly Sanitation</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Wash/Rinse/Sanitize - Produce Tubs</td>\n",
       "      <td>Weekly Sanitation</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Deep Clean - Floor Drains</td>\n",
       "      <td>Weekly Sanitation</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Spray and Wipe - Wipe Down Walls Behind Cut Fr...</td>\n",
       "      <td>Weekly Sanitation</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Spray and Wipe - Bottom Pan of Refrigeration C...</td>\n",
       "      <td>Weekly Sanitation</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Floral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  div_str_id_s                                          task_desc  \\\n",
       "0     53100515                           Deep Clean - Knife Racks   \n",
       "1     53100515                 Wash/Rinse/Sanitize - Produce Tubs   \n",
       "2     53100515                          Deep Clean - Floor Drains   \n",
       "3     53100515  Spray and Wipe - Wipe Down Walls Behind Cut Fr...   \n",
       "4     53100515  Spray and Wipe - Bottom Pan of Refrigeration C...   \n",
       "\n",
       "      task_type_name task_type_name task_classification_s sub_dpmt_name  \n",
       "0  Weekly Sanitation     Sanitation                Weekly          Meat  \n",
       "1  Weekly Sanitation     Sanitation                Weekly       Produce  \n",
       "2  Weekly Sanitation     Sanitation                Weekly        Bakery  \n",
       "3  Weekly Sanitation     Sanitation                Weekly       Produce  \n",
       "4  Weekly Sanitation     Sanitation                Weekly        Floral  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ws_s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6927d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_ws_s_df.to_csv(\"C:\\\\Users\\\\AS81970\\\\Desktop\\\\tm_ws_s.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed2eab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target data\n",
    "with database_2.snapshot() as snapshot:\n",
    "    result = snapshot.execute_sql(\"\"\"\n",
    "select \n",
    "concat(division_number,store_number) AS div_str_id,\n",
    "task_type, task_classification, department_name, task_description\n",
    "from task\n",
    "where task_type<>'Green Rack' \n",
    "and task_classification  like 'Weekly'\n",
    "and task_date='2023-09-05'\n",
    "and task_type='Sanitation'\n",
    "and concat(division_number, store_number) = '53100515'\n",
    "        \"\"\")\n",
    "    \n",
    "    \n",
    "    # Stream in rows\n",
    "    rows = list()\n",
    "    for row in result:\n",
    "        rows.append(row)\n",
    "\n",
    "    # Get column names\n",
    "    cols = [x.name for x in result.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_ws_t_df = pd.DataFrame(rows, columns = cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb25af96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div_str_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_classification</th>\n",
       "      <th>department_name</th>\n",
       "      <th>task_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Deep Clean - Floor Drains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Produce</td>\n",
       "      <td>Spray and Wipe - Refrigerated Island Cases inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Clean - Glass Doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Floral</td>\n",
       "      <td>Spray and Wipe - Floral Display Case Doors, Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53100515</td>\n",
       "      <td>Sanitation</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Spot Clean - Beef, Pork, &amp; Poultry Display Cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  div_str_id   task_type task_classification department_name  \\\n",
       "0   53100515  Sanitation              Weekly            Meat   \n",
       "1   53100515  Sanitation              Weekly         Produce   \n",
       "2   53100515  Sanitation              Weekly          Frozen   \n",
       "3   53100515  Sanitation              Weekly          Floral   \n",
       "4   53100515  Sanitation              Weekly            Meat   \n",
       "\n",
       "                                    task_description  \n",
       "0                          Deep Clean - Floor Drains  \n",
       "1  Spray and Wipe - Refrigerated Island Cases inc...  \n",
       "2                                Clean - Glass Doors  \n",
       "3  Spray and Wipe - Floral Display Case Doors, Ha...  \n",
       "4  Spot Clean - Beef, Pork, & Poultry Display Cas...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ws_t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92c522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c14006c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Sanitation Validation Report Passed\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'div_str_id' and 'task_desc'\n",
    "ws_merged_df = pd.merge(result_s_df, result_t_df, left_on=['div_str_id_s', 'task_desc'], right_on=['div_str_id', 'task_description'], how='outer')\n",
    "\n",
    "# Create a new column 'ComparisonResult' based on your conditions\n",
    "ws_merged_df['ComparisonResult'] = 'Mismatch'\n",
    "\n",
    "# Condition 1: Matched\n",
    "condition_matched = (\n",
    "    (ws_merged_df['task_type_name'] == ws_merged_df['task_type']) &\n",
    "    (ws_merged_df['task_classification_s'] == ws_merged_df['task_classification']) &\n",
    "    #(ws_merged_df['sub_dpmt_name'] == ws_merged_df['department_name']) &\n",
    "    (ws_merged_df['task_desc'] == ws_merged_df['task_description'])\n",
    "    #(ws_merged_df['concatenated_s'] == ws_merged_df['concatenated_t'])\n",
    ")\n",
    "ws_merged_df.loc[condition_matched, 'ComparisonResult'] = 'Matched'\n",
    "\n",
    "# Condition 2: Record NOT in Target\n",
    "condition_not_in_target = (ws_merged_df['div_str_id_s'].notna()) & (ws_merged_df['div_str_id'].isna())\n",
    "ws_merged_df.loc[condition_not_in_target, 'ComparisonResult'] = 'Record NOT in Target'\n",
    "\n",
    "# Condition 3: Record NOT in Source\n",
    "condition_not_in_source = (ws_merged_df['div_str_id'].notna()) & (ws_merged_df['div_str_id_s'].isna())\n",
    "ws_merged_df.loc[condition_not_in_source, 'ComparisonResult'] = 'Record NOT in Source'\n",
    "\n",
    "# Remove duplicates from ws_merged_df\n",
    "ws_merged_df = ws_merged_df.drop_duplicates()\n",
    "\n",
    "# Reset the index after removing duplicates (optional)\n",
    "ws_merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if there are any failed records\n",
    "if not failed_records.empty:\n",
    "    print('Weekly Sanitation Validation Report Failed')\n",
    "\n",
    "    # Get the current date as a timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Define the full path to save the report file\n",
    "    file_path = r'C:\\\\Users\\\\AS81970\\\\Desktop\\\\2023 Q3\\\\Store Walk-in\\\\Reports'\n",
    "    \n",
    "    # Define the file name with the date appended\n",
    "    report_file_name = f'Weekly_Sanitation_Validation_Report_Failed_{timestamp}.xlsx'\n",
    "    \n",
    "    # Save the failed records to an Excel file with the generated file name\n",
    "    failed_records.to_excel(f'{file_path}\\\\{report_file_name}', index=False)\n",
    "else:\n",
    "    print('Weekly Sanitation Validation Report Passed')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81478206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcadda",
   "metadata": {},
   "outputs": [],
   "source": [
    " #results_ws_s_c_df.to_csv(file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3626fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98eb6be",
   "metadata": {},
   "source": [
    "## 3) Weekly Rotation Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b544c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c23fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397092b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93092d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f6869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121eddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7851517c",
   "metadata": {},
   "source": [
    "## 4) 3xWeekly Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0738e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0bd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a32e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b89a0ea4",
   "metadata": {},
   "source": [
    "## 5) Periodic Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec365245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac904ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22abb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf87bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee8c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29448730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eb86ef4",
   "metadata": {},
   "source": [
    "## 6) Quaterly Counts & Data Validation between source and target ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccee83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd471f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d872c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401098f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc8b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a43d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b481485",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts_Report_Date \n",
    " Daily count Source - Done\n",
    " Daily count Target - Done\n",
    " Weekly Sanitation count Source - \n",
    " Weekly Sanitation count Target -\n",
    " Weekly Rotation count Source - \n",
    " Weekly Rotation count Target - \n",
    " 3xWeekly count Source - \n",
    " 3xWeekly count Target - \n",
    " Periodic count Source - \n",
    " Periodic count Target - \n",
    " \n",
    " ------------------------\n",
    "Daily_Validation_Report_Date - Done\n",
    "Weekly_Sanitation_Validation_Report_Date - Done\n",
    "Weekly_Rotation_Validation_Report_Date\n",
    "3xWeekly_ReportValidation_Report_Date\n",
    "Periodic_Validation_Report_Date\n",
    "Quaterly_Validation_Report_Date\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305dbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv(\"C:\\\\Users\\\\AS81970\\\\Desktop\\\\tm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
